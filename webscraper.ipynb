{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m pip install facebook-page-scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "import csv\n",
    "\n",
    "from selenium.webdriver.chrome.webdriver import WebDriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#chrome WebDriver\n",
    "service = Service('chromedriver path')  # Update with chromedriver path\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "#Navigate to the main login page\n",
    "driver.get('main login page here')\n",
    "\n",
    "#Credentials  \n",
    "email_input = driver.find_element(By.ID, 'email')  \n",
    "email_input.send_keys('email here ')  \n",
    "password_input = driver.find_element(By.ID, 'pass')  \n",
    "password_input.send_keys('psword')  \n",
    "password_input.send_keys(Keys.RETURN)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_file(post_array):\n",
    "    # Write data to CSV\n",
    "    with open('facebook_posts.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['URL', 'Content', 'Date'])\n",
    "        \n",
    "        for row in post_array:\n",
    "            writer.writerow(post_array)\n",
    "\n",
    "\n",
    "# Navigate to the page to scrape\n",
    "driver.get('page here')\n",
    "\n",
    "all_posts = []\n",
    "\n",
    "# Scroll down to load more posts\n",
    "for i in range(2):  #Increase if have more posts to load\n",
    "    driver.find_element(By.XPATH, '//body').send_keys(Keys.END)\n",
    "    time.sleep(1) \n",
    "\n",
    "    # Extract post data\n",
    "    posts = driver.find_elements_by_xpath('/html/body/div[1]/div/div[1]/div/div[3]/div/div/div[1]/div[1]/div/div/div[4]/div[2]/div/div[2]/div[3]/*')\n",
    "\n",
    "    for post in posts:\n",
    "        try:\n",
    "            # TODO get the date from the post, also the post ID would be good\n",
    "\n",
    "            post_url = 12345 #placeholder in csv for now\n",
    "            post_content = post.text\n",
    "            post_date = 1234\n",
    "\n",
    "            all_posts.append([post_url, post_content, post_date])\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "    if i % 10:\n",
    "        save_to_file(all_posts)\n",
    "\n",
    "save_to_file(all_posts)\n",
    "\n",
    "#next steps: need to find xpath for post dates and the post ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
